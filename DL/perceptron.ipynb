{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data[:100]\n",
    "y = iris.target[:100] # labels - 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to PyTorch tensors\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test = torch.tensor(X_train, dtype=torch.float32), torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train, y_test = torch.tensor(y_train, dtype=torch.float32).view(-1, 1), torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the perceptron model\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 1)  # linear layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc(x))  # sigmoid activation\n",
    "\n",
    "# initialize model, loss function, and optimizer\n",
    "model = Perceptron(input_size=4)\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Loss: 0.2421, Accuracy: 100.00%\n",
      "Epoch [20/500], Loss: 0.2319, Accuracy: 100.00%\n",
      "Epoch [30/500], Loss: 0.2224, Accuracy: 100.00%\n",
      "Epoch [40/500], Loss: 0.2137, Accuracy: 100.00%\n",
      "Epoch [50/500], Loss: 0.2056, Accuracy: 100.00%\n",
      "Epoch [60/500], Loss: 0.1981, Accuracy: 100.00%\n",
      "Epoch [70/500], Loss: 0.1911, Accuracy: 100.00%\n",
      "Epoch [80/500], Loss: 0.1846, Accuracy: 100.00%\n",
      "Epoch [90/500], Loss: 0.1785, Accuracy: 100.00%\n",
      "Epoch [100/500], Loss: 0.1727, Accuracy: 100.00%\n",
      "Epoch [110/500], Loss: 0.1674, Accuracy: 100.00%\n",
      "Epoch [120/500], Loss: 0.1623, Accuracy: 100.00%\n",
      "Epoch [130/500], Loss: 0.1576, Accuracy: 100.00%\n",
      "Epoch [140/500], Loss: 0.1531, Accuracy: 100.00%\n",
      "Epoch [150/500], Loss: 0.1488, Accuracy: 100.00%\n",
      "Epoch [160/500], Loss: 0.1448, Accuracy: 100.00%\n",
      "Epoch [170/500], Loss: 0.1410, Accuracy: 100.00%\n",
      "Epoch [180/500], Loss: 0.1374, Accuracy: 100.00%\n",
      "Epoch [190/500], Loss: 0.1340, Accuracy: 100.00%\n",
      "Epoch [200/500], Loss: 0.1307, Accuracy: 100.00%\n",
      "Epoch [210/500], Loss: 0.1276, Accuracy: 100.00%\n",
      "Epoch [220/500], Loss: 0.1247, Accuracy: 100.00%\n",
      "Epoch [230/500], Loss: 0.1218, Accuracy: 100.00%\n",
      "Epoch [240/500], Loss: 0.1191, Accuracy: 100.00%\n",
      "Epoch [250/500], Loss: 0.1165, Accuracy: 100.00%\n",
      "Epoch [260/500], Loss: 0.1141, Accuracy: 100.00%\n",
      "Epoch [270/500], Loss: 0.1117, Accuracy: 100.00%\n",
      "Epoch [280/500], Loss: 0.1094, Accuracy: 100.00%\n",
      "Epoch [290/500], Loss: 0.1073, Accuracy: 100.00%\n",
      "Epoch [300/500], Loss: 0.1052, Accuracy: 100.00%\n",
      "Epoch [310/500], Loss: 0.1032, Accuracy: 100.00%\n",
      "Epoch [320/500], Loss: 0.1012, Accuracy: 100.00%\n",
      "Epoch [330/500], Loss: 0.0994, Accuracy: 100.00%\n",
      "Epoch [340/500], Loss: 0.0976, Accuracy: 100.00%\n",
      "Epoch [350/500], Loss: 0.0958, Accuracy: 100.00%\n",
      "Epoch [360/500], Loss: 0.0942, Accuracy: 100.00%\n",
      "Epoch [370/500], Loss: 0.0925, Accuracy: 100.00%\n",
      "Epoch [380/500], Loss: 0.0910, Accuracy: 100.00%\n",
      "Epoch [390/500], Loss: 0.0895, Accuracy: 100.00%\n",
      "Epoch [400/500], Loss: 0.0880, Accuracy: 100.00%\n",
      "Epoch [410/500], Loss: 0.0866, Accuracy: 100.00%\n",
      "Epoch [420/500], Loss: 0.0853, Accuracy: 100.00%\n",
      "Epoch [430/500], Loss: 0.0840, Accuracy: 100.00%\n",
      "Epoch [440/500], Loss: 0.0827, Accuracy: 100.00%\n",
      "Epoch [450/500], Loss: 0.0814, Accuracy: 100.00%\n",
      "Epoch [460/500], Loss: 0.0802, Accuracy: 100.00%\n",
      "Epoch [470/500], Loss: 0.0791, Accuracy: 100.00%\n",
      "Epoch [480/500], Loss: 0.0779, Accuracy: 100.00%\n",
      "Epoch [490/500], Loss: 0.0768, Accuracy: 100.00%\n",
      "Epoch [500/500], Loss: 0.0758, Accuracy: 100.00%\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        acc = (predictions == y_train).float().mean()\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Accuracy: {acc.item() * 100:.2f}%')\n",
    "\n",
    "# testing the model\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    test_predictions = (test_outputs > 0.5).float()\n",
    "    test_acc = (test_predictions == y_test).float().mean()\n",
    "    print(f'Test Accuracy: {test_acc.item() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0\n"
     ]
    }
   ],
   "source": [
    "# sample prediction\n",
    "new_sample = np.array([[5.0, 3.5, 1.3, 0.3]]) \n",
    "new_sample = scaler.transform(new_sample)\n",
    "new_sample_tensor = torch.tensor(new_sample, dtype=torch.float32)\n",
    "\n",
    "# predict\n",
    "with torch.no_grad():\n",
    "    prediction = model(new_sample_tensor)\n",
    "    predicted_class = (prediction > 0.5).float().item()\n",
    "    print(f'Predicted Class: {int(predicted_class)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
